{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpMZbjlXeBf3",
        "outputId": "bd43b085-e1bc-49cd-edc7-9c4fe07c927e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (22.0.4)\n",
            "Collecting pip\n",
            "  Downloading pip-23.0.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.4\n",
            "    Uninstalling pip-22.0.4:\n",
            "      Successfully uninstalled pip-22.0.4\n",
            "Successfully installed pip-23.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.6\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting nltk==3.4\n",
            "  Downloading nltk-3.4.zip (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from nltk==3.4) (1.16.0)\n",
            "Collecting singledispatch\n",
            "  Downloading singledispatch-4.0.0-py2.py3-none-any.whl (9.2 kB)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4-py3-none-any.whl size=1436395 sha256=734da6eb98c2fc959edbda84745caf2002f74dbc61077e739bb6f71e71d60cea\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/96/da/0a26fbd3f96b179cc14b813434a0c324a08c0684afdd524c73\n",
            "Successfully built nltk\n",
            "Installing collected packages: singledispatch, nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed nltk-3.4 singledispatch-4.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# 安装依赖\n",
        "!pip install -U pip\n",
        "!pip install -U dill\n",
        "!pip install -U nltk==3.4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 本notebook中使用 lm 和 nltk 进行 N-Gram 模型的训练和生成\n",
        "- 导入依赖\n",
        "- 我们会从简单的句子开始了解如何使用nltk进行分词和分词预处理的操作\n",
        "- 之后我们会引入真实的数据集进行操作和训练"
      ],
      "metadata": {
        "id": "0YKEx9Wjf_0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten"
      ],
      "metadata": {
        "id": "BkyHIAAUe7MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 如果想要训练一个 2-gram 模型，首先需要将一段文本转化为 2-gran 的格式\n",
        "- 看一个例子"
      ],
      "metadata": {
        "id": "VIPewLkof8ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text = [['a', 'b', 'c'], ['a', 'c', 'd', 'c', 'e', 'f']]\n",
        "list(bigrams(text[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij0xFG9ofQI3",
        "outputId": "e4848ad5-61f2-4a92-bf9f-814941a5942f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 'b'), ('b', 'c')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(ngrams(text[1], n = 3)) # 3-Gram 进行分词"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9LxgZXWgDLk",
        "outputId": "ff227e1f-5b73-4456-e1db-7ba049059f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 'c', 'd'), ('c', 'd', 'c'), ('d', 'c', 'e'), ('c', 'e', 'f')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 在文本text1中，我们发现分词之后的文本组，b作为分词组的head和tail分别出现了两次，但是 a 和 c 则只出现了一次\n",
        "- 是否有办法将 a 和 c 作为原句中 head 和 tail 的关系表达出来呢？\n",
        "- 可以通过使用 padding 符号的方式补全原句中的开头和结尾，补全后再进行分词操作\n",
        "- padding 符号中使用`<s>` 作为head标签，`</s>`作为tail标签"
      ],
      "metadata": {
        "id": "UkId_7s4gLiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 注意n代表了将会使用n-gram进行分词，参数n决定了需要填充多少 padding symbol\n",
        "# n = 2时需要填充一前一后两个symbol，n=3时则需要填充两前两后4个symbol，以此类推，\n",
        "from nltk.util import pad_sequence\n",
        "list(pad_sequence(text[0],\n",
        "        pad_left = True, left_pad_symbol='<s>',\n",
        "        pad_right = True, right_pad_symbol= '</s>',\n",
        "        n=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSVFML4vgJvc",
        "outputId": "8477ec66-4be1-4c9f-86e9-cd7fa3b7a593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'a', 'b', 'c', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sent = list(pad_sequence(text[0], \n",
        "                pad_left=True, left_pad_symbol=\"<s>\", \n",
        "                pad_right=True, right_pad_symbol=\"</s>\", \n",
        "                n=2))\n",
        "list(ngrams(padded_sent, n=2)) # 对padding之后的文本序列进行分词"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTDXAeqohrZW",
        "outputId": "cf8b548d-0ac1-4261-9546-c90ba6099b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<s>', 'a'), ('a', 'b'), ('b', 'c'), ('c', '</s>')]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(pad_sequence(text[0],\n",
        "        pad_left=True, left_pad_symbol=\"<s>\",\n",
        "        pad_right=True, right_pad_symbol=\"</s>\",\n",
        "        n=3))\n",
        "# 因为进行3-Gram的操作，所以这里填充的是两前两后                "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJpioiuWjVyw",
        "outputId": "cf9608cc-d5b9-4356-86bd-5792aa844239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', '<s>', 'a', 'b', 'c', '</s>', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sent = list(pad_sequence(text[0], \n",
        "        pad_left=True, left_pad_symbol=\"<s>\", \n",
        "        pad_right=True, right_pad_symbol=\"</s>\", n=3))\n",
        "list(ngrams(padded_sent, n=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECbghhWqjsaC",
        "outputId": "deab874e-21aa-4833-f53d-fd6ac7997fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<s>', '<s>', 'a'),\n",
              " ('<s>', 'a', 'b'),\n",
              " ('a', 'b', 'c'),\n",
              " ('b', 'c', '</s>'),\n",
              " ('c', '</s>', '</s>')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nltk.lm 提供了上述代码的简化版本"
      ],
      "metadata": {
        "id": "fuVjl7-hle-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "list(pad_both_ends(text[0],n = 2)) # 2-Gram 填充"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIgVSFyHko3J",
        "outputId": "07abd201-8fee-4d7b-d68c-58ba07a1bcea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'a', 'b', 'c', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(bigrams(pad_both_ends(text[0],n=2))) # 2-Gram 分词"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRY29_ygl0Aj",
        "outputId": "4d5f35d3-ce6b-4ed4-9a8f-930ab02ccb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<s>', 'a'), ('a', 'b'), ('b', 'c'), ('c', '</s>')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 通过NLTK，我们可以更加便捷的方式处理N-Gram，而不需要通过指定N作为具体的参数进行分词"
      ],
      "metadata": {
        "id": "dOCiiNtPvKno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import everygrams\n",
        "padded_bigrams = list(pad_both_ends(text[0], n = 2))\n",
        "list(everygrams(padded_bigrams,max_len=2)) # 除了可以生成1-gram，还可以生成2-Gram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8-pyiTLl8nV",
        "outputId": "4dc2c061-8f77-43b4-deb8-335ffec2de35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<s>',),\n",
              " ('a',),\n",
              " ('b',),\n",
              " ('c',),\n",
              " ('</s>',),\n",
              " ('<s>', 'a'),\n",
              " ('a', 'b'),\n",
              " ('b', 'c'),\n",
              " ('c', '</s>')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import everygrams\n",
        "padded_bigrams = list(pad_both_ends(text[0], n = 3))\n",
        "list(everygrams(padded_bigrams,max_len=3)) # 除了可以生成1-gram，还可以生成2-Gram 和 3-Gram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6osfVEGvs77",
        "outputId": "8df552a5-08c2-4139-ad61-5014bdf53fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('<s>',),\n",
              " ('<s>',),\n",
              " ('a',),\n",
              " ('b',),\n",
              " ('c',),\n",
              " ('</s>',),\n",
              " ('</s>',),\n",
              " ('<s>', '<s>'),\n",
              " ('<s>', 'a'),\n",
              " ('a', 'b'),\n",
              " ('b', 'c'),\n",
              " ('c', '</s>'),\n",
              " ('</s>', '</s>'),\n",
              " ('<s>', '<s>', 'a'),\n",
              " ('<s>', 'a', 'b'),\n",
              " ('a', 'b', 'c'),\n",
              " ('b', 'c', '</s>'),\n",
              " ('c', '</s>', '</s>')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 在模型的训练和evaluation 期间，模型高度依赖于基于数据集的词汇表，因此，我们还需要定义模型的词汇表"
      ],
      "metadata": {
        "id": "ae30LnTTwAtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm.preprocessing import flatten\n",
        "list(flatten(pad_both_ends(sent, n=2) for sent in text)) # 将text中的文本转化为词汇表，但是不做去重处理，这里是生成corpus的过程，而不是支持字典表的过程"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TBszHVzv3gg",
        "outputId": "c85f7a31-cbd0-4bcd-891e-2ba0ed46d126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>', 'a', 'b', 'c', '</s>', '<s>', 'a', 'c', 'd', 'c', 'e', 'f', '</s>']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 上述过程我们分别进行了三个步骤的操作\n",
        "1. 将文本句子基于 N-gram 进行padding补齐\n",
        "2. 将句子进行分词\n",
        "3. 将句子的构成转化为词汇表\n",
        "\n",
        "- 有没有什么办法可以让这三部过程更加简单？"
      ],
      "metadata": {
        "id": "OxCbzcXCwZgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm.preprocessing import padded_everygram_pipeline \n",
        "# 分别生成N-Gram的文本分词结果和词汇表\n",
        "# 生成的结果都是 iterators 对象\n",
        "training_ngrams, padded_sentences = padded_everygram_pipeline(2, text)\n",
        "for ngramlize_sent in training_ngrams:\n",
        "    print('分词结果:',list(ngramlize_sent))\n",
        "    print()\n",
        "print('--------------split line---------------')\n",
        "print('词汇表',list(padded_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW0yqT5cwTe6",
        "outputId": "c7c19cb7-cebf-4331-b56c-66c51a0ebb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "分词结果: [('<s>',), ('a',), ('b',), ('c',), ('</s>',), ('<s>', 'a'), ('a', 'b'), ('b', 'c'), ('c', '</s>')]\n",
            "\n",
            "分词结果: [('<s>',), ('a',), ('c',), ('d',), ('c',), ('e',), ('f',), ('</s>',), ('<s>', 'a'), ('a', 'c'), ('c', 'd'), ('d', 'c'), ('c', 'e'), ('e', 'f'), ('f', '</s>')]\n",
            "\n",
            "--------------split line---------------\n",
            "词汇表 ['<s>', 'a', 'b', 'c', '</s>', '<s>', 'a', 'c', 'd', 'c', 'e', 'f', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 进入真实数据环节"
      ],
      "metadata": {
        "id": "2hRwG26Uzcjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:  # 使用默认的NLTK分词器\n",
        "    from nltk import word_tokenize, sent_tokenize \n",
        "    # 确认分词器是否可用，在某些机器上可能会因为setpup的问题而invalid\n",
        "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
        "except: # 在上述工具无法使用的时候，使用原始的分词器方式进行分词\n",
        "    import re\n",
        "    from nltk.tokenize import ToktokTokenizer\n",
        "    # 具体原因可查看 https://stackoverflow.com/a/25736515/610569\n",
        "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
        "    # ToktokTokenizer 是内建的分词器，所以无需引入即可使用\n",
        "    toktok = ToktokTokenizer()\n",
        "    word_tokenize = word_tokenize = toktok.tokenize"
      ],
      "metadata": {
        "id": "Jv3100mlwxl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import io #codecs\n",
        "# 下载文本数据\n",
        "url = \"https://gist.githubusercontent.com/alvations/53b01e4076573fea47c6057120bb017a/raw/b01ff96a5f76848450e648f35da6497ca9454e4a/language-never-random.txt\"\n",
        "text = requests.get(url).content.decode('utf8')\n",
        "with io.open('language-never-random.txt', 'w', encoding='utf8') as fout:\n",
        "    fout.write(text)"
      ],
      "metadata": {
        "id": "kVHtXGM6z8Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 查看下载下来的文本\n",
        "\n",
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOVA12Ae18Vz",
        "outputId": "349eaf42-2dee-4dcc-ec80-aedc27c53e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Language is never, ever, ever, random\n",
            "\n",
            "                                                               ADAM KILGARRIFF\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Abstract\n",
            "Language users never choose words randomly, and language is essentially\n",
            "non-random. Statistical hypothesis testing uses a null hypothesis, which\n",
            "posits randomness. Hence, when we look at linguistic phenomena in cor-\n",
            "pora, the null hypothesis will never be true. Moreover, where there is enough\n",
            "data, we shall (almost) always be able to establish \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 将文本进行标签化处理\n",
        "\n",
        "tokenized_text = [list(map(str.lower, word_tokenize(sent))) for sent in sent_tokenize(text)]\n",
        "len(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_LHCrOg0LC4",
        "outputId": "b46cf8f0-edb4-45d2-f8a7-5c5b3fe53690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxj-8Hnl1eIZ",
        "outputId": "71ddbd73-40f9-4e6a-aa74-55fc98e5e48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['language',\n",
              " 'is',\n",
              " 'never',\n",
              " ',',\n",
              " 'ever',\n",
              " ',',\n",
              " 'ever',\n",
              " ',',\n",
              " 'random',\n",
              " 'adam',\n",
              " 'kilgarriff',\n",
              " 'abstract',\n",
              " 'language',\n",
              " 'users',\n",
              " 'never',\n",
              " 'choose',\n",
              " 'words',\n",
              " 'randomly',\n",
              " ',',\n",
              " 'and',\n",
              " 'language',\n",
              " 'is',\n",
              " 'essentially',\n",
              " 'non-random',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用every-grams 上限为3作为参数，生成分词数据\n",
        "n = 3\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_text)"
      ],
      "metadata": {
        "id": "cWR1ZtyS1gYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 这里我们使用最大似然估计 MLE 的方式进行模型的训练\n",
        "- MLE的初始化使用N-Gram的N值进行"
      ],
      "metadata": {
        "id": "3-G4uW0D3M3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import MLE\n",
        "model = MLE(n) # Lets train a 3-grams model, previously we set n=3"
      ],
      "metadata": {
        "id": "hqbao_WR2Lds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化后MLE创建一个空的字典表，注意不是词汇表，是字典表\n",
        "\n",
        "len(model.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAp-Qh9C3ZCf",
        "outputId": "ef209a5b-0cd2-4662-9b1d-5a6e213a6fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, padded_sents)"
      ],
      "metadata": {
        "id": "F5alz9KT4LSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.vocab) # 未知的文本使用 UNK 进行代替"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATLoisrE4QA-",
        "outputId": "5c6153f4-6f97-47c4-89e1-c7cebb246d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Vocabulary with cutoff=1 unk_label='<UNK>' and 1429 items>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.vocab.lookup(tokenized_text[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CwVfJHd4R_3",
        "outputId": "96de850c-e2ba-4aef-80a3-c1b750681ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('language', 'is', 'never', ',', 'ever', ',', 'ever', ',', 'random', 'adam', 'kilgarriff', 'abstract', 'language', 'users', 'never', 'choose', 'words', 'randomly', ',', 'and', 'language', 'is', 'essentially', 'non-random', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 当我们查找训练集中不存在的词汇时，会返回一个 <UNK> 标签作为代替\n",
        "\n",
        "print(model.vocab.lookup('language is never random lah .'.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5diEjVAr5km-",
        "outputId": "16c09011-8b56-4d65-98ec-8fb560a8f1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('language', 'is', 'never', 'random', '<UNK>', '.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.counts) # 基于3—Gram进行分词"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBwkVeNB6A-Y",
        "outputId": "f855aa34-3f53-4911-fb40-f6d997f7c1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<NgramCounter with 3 ngram orders and 18687 ngrams>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.counts['language'] # 计算language这个字在corpus中的数量"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4e7MU5I8ANe",
        "outputId": "67f30540-4629-4622-c7c5-8a15c4981f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算‘language is' 这个 2-Gram 短语的出现频次\n",
        "model.counts[['language']]['is'] #  Count('is'|'language')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQgGwogH8LXN",
        "outputId": "2d86defd-0f15-4ea2-f943-33229ac30ab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算‘language is never' 这个 3-Gram 短语出现的频次\n",
        "model.counts[['language', 'is']]['never'] # Count('never'|'language is')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNeb9WxX89HQ",
        "outputId": "6dee7a54-9d15-4df3-9084-d3e0f200fabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 训练语言模型的真正目的是让它对特定上下文中的单词概率进行评分\n",
        "- 从而帮助我们选择更合适的候选词\n",
        "- MLE 中会返回相关频率作为得分"
      ],
      "metadata": {
        "id": "pU6EPnDH9Obx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.score('language') # P('language')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMHFUfkt9K_o",
        "outputId": "56fbc8c9-52e3-4167-f3bf-8bb7eb959aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.003916040100250626"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score('is', 'language'.split())  # P('is'|'language')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sffltfe09nci",
        "outputId": "0e5a0159-411c-4b47-bdc2-caf78d38ee34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score('never', 'language is'.split())  # P('never'|'language is')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkD3I1wq9oYA",
        "outputId": "7cd82075-e59c-426b-cdf1-957aaabba221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6363636363636364"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 需要注意的是，没有出现文本数据集中的单词会被识别为 `<UNK>`"
      ],
      "metadata": {
        "id": "d109Bl9A92RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(\"<UNK>\") == model.score(\"lah\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtkvxhGV91nc",
        "outputId": "63c90d5e-b63d-44c8-a9ac-cf74f497bc78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(\"<UNK>\") == model.score(\"leh\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hf2jio9-A2_",
        "outputId": "e90e1daa-41b2-4984-9332-8277caa02488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.score(\"<UNK>\") == model.score(\"lor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt2blIE--B7f",
        "outputId": "37280542-d2f5-46c7-ed03-d43ee53f1405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用 N-Gram 生成文本"
      ],
      "metadata": {
        "id": "nlh2xT5g-27W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.generate(20, random_seed=7)) # 让模型生成20个字的文本序列"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pklEvXl-C_A",
        "outputId": "0f19d3e0-da48-4e8d-c07c-f1b2c759d8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ate', 'inferences', 'are', 'drawn.', '2', '.', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 生成的文本存在大量无意义的head tail symbol\n",
        "- 对生成的过程可以进行一下处理"
      ],
      "metadata": {
        "id": "uted3KXgAcbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "detokenize = TreebankWordDetokenizer().detokenize # 对于文本的解码，将tokenize化的文本转化为正常的输出文本\n",
        "\n",
        "def generate_sent(model, num_words, random_seed = 42):\n",
        "  # model 接收 N-Grammodel\n",
        "  # num_words 期待生产的文本长度\n",
        "  # random_seed 随机种子\n",
        "  content = []\n",
        "  for token in model.generate(num_words, random_seed=random_seed):\n",
        "    if token == '<s>':\n",
        "      continue\n",
        "    if token == '</s>':\n",
        "      break\n",
        "\n",
        "    content.append(token)\n",
        "  return detokenize(content)\n",
        "\n",
        "generate_sent(model,20,random_seed=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sXWG1fAb-61R",
        "outputId": "f6b426c9-2a95-4b0d-9358-3c6018b29564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ate inferences are drawn. 2.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.generate(28, random_seed=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8wgKRJ4D9wf",
        "outputId": "20ec0439-ddb0-4d01-979b-a2ef3f9cf01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'trouble', 'with', 'quantitative', 'studies', '.', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(model, 20, random_seed=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "MBCgZWFoEBEo",
        "outputId": "a58a8119-0f76-4404-b486-36a65d26cf4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'29⫺50. manning, christopher and hinrich schütze 1999 foundations of statistical independence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(model, 20, random_seed=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WlfFeHBuEHwy",
        "outputId": "b0ed2d2e-084c-45df-8f19-5f1907ae2fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'information glut, is inappropriate, particularly where counts are low.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 虽然文本生成了，但是文本生成的效果只能说一言难尽"
      ],
      "metadata": {
        "id": "p1VKFDIzESxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 使用特朗普的推特进行文本生成"
      ],
      "metadata": {
        "id": "XU-XGZJqFSdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [数据集下载地址](https://www.kaggle.com/datasets/kingburrito666/better-donald-trump-tweets)"
      ],
      "metadata": {
        "id": "ZkmU4oHjF8j1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('Donald-Tweets!.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "XOPsq2q8EQXN",
        "outputId": "291efe3e-adb6-4d53-fa9c-3b9bce988ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Date      Time                                         Tweet_Text  \\\n",
              "0  16-11-11  15:26:37  Today we express our deepest gratitude to all ...   \n",
              "1  16-11-11  13:33:35  Busy day planned in New York. Will soon be mak...   \n",
              "2  16-11-11  11:14:20  Love the fact that the small groups of protest...   \n",
              "3  16-11-11   2:19:44  Just had a very open and successful presidenti...   \n",
              "4  16-11-11   2:10:46  A fantastic day in D.C. Met with President Oba...   \n",
              "\n",
              "   Type Media_Type   Hashtags      Tweet_Id  \\\n",
              "0  text      photo  ThankAVet  7.970000e+17   \n",
              "1  text        NaN        NaN  7.970000e+17   \n",
              "2  text        NaN        NaN  7.970000e+17   \n",
              "3  text        NaN        NaN  7.970000e+17   \n",
              "4  text        NaN        NaN  7.970000e+17   \n",
              "\n",
              "                                           Tweet_Url  \\\n",
              "0  https://twitter.com/realDonaldTrump/status/797...   \n",
              "1  https://twitter.com/realDonaldTrump/status/797...   \n",
              "2  https://twitter.com/realDonaldTrump/status/797...   \n",
              "3  https://twitter.com/realDonaldTrump/status/796...   \n",
              "4  https://twitter.com/realDonaldTrump/status/796...   \n",
              "\n",
              "   twt_favourites_IS_THIS_LIKE_QUESTION_MARK  Retweets  Unnamed: 10  \\\n",
              "0                                     127213     41112          NaN   \n",
              "1                                     141527     28654          NaN   \n",
              "2                                     183729     50039          NaN   \n",
              "3                                     214001     67010          NaN   \n",
              "4                                     178499     36688          NaN   \n",
              "\n",
              "   Unnamed: 11  \n",
              "0          NaN  \n",
              "1          NaN  \n",
              "2          NaN  \n",
              "3          NaN  \n",
              "4          NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-671a5678-16a5-4c52-9f1b-b7c8c973197f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Tweet_Text</th>\n",
              "      <th>Type</th>\n",
              "      <th>Media_Type</th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>Tweet_Id</th>\n",
              "      <th>Tweet_Url</th>\n",
              "      <th>twt_favourites_IS_THIS_LIKE_QUESTION_MARK</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>15:26:37</td>\n",
              "      <td>Today we express our deepest gratitude to all ...</td>\n",
              "      <td>text</td>\n",
              "      <td>photo</td>\n",
              "      <td>ThankAVet</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>127213</td>\n",
              "      <td>41112</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>13:33:35</td>\n",
              "      <td>Busy day planned in New York. Will soon be mak...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>141527</td>\n",
              "      <td>28654</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>11:14:20</td>\n",
              "      <td>Love the fact that the small groups of protest...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>183729</td>\n",
              "      <td>50039</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>2:19:44</td>\n",
              "      <td>Just had a very open and successful presidenti...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
              "      <td>214001</td>\n",
              "      <td>67010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>2:10:46</td>\n",
              "      <td>A fantastic day in D.C. Met with President Oba...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
              "      <td>178499</td>\n",
              "      <td>36688</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-671a5678-16a5-4c52-9f1b-b7c8c973197f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-671a5678-16a5-4c52-9f1b-b7c8c973197f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-671a5678-16a5-4c52-9f1b-b7c8c973197f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 我们需要使用 twitter 正文\n",
        "trump_corpus = list(df['Tweet_Text'].apply(word_tokenize))\n",
        "n = 3\n",
        "train_data, padded_sents = padded_everygram_pipeline(n, trump_corpus)"
      ],
      "metadata": {
        "id": "Qwuy-Lv_GZ7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.lm import MLE\n",
        "trump_model = MLE(n) # Lets train a 3-grams model, previously we set n=3\n",
        "trump_model.fit(train_data, padded_sents)"
      ],
      "metadata": {
        "id": "OQUDuNtAG3BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(trump_model, num_words=20, random_seed=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gaqTQ_iYG4W7",
        "outputId": "fd37be11-88f9-4d61-f351-f7e3229e719b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'do so many people on television. Just another desperate move by the media pile on against me in Rome ,'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_sent(trump_model, num_words=50, random_seed=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vDiPxrSZG6k1",
        "outputId": "2ca86547-e155-48b4-91a5-8bdb73e891fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'and many other subjects! Bad times for divided USA! +Israel2 \"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- N-Gram 作为一个基于统计的语言模型，他的文本生成能力不要抱有太大的期望"
      ],
      "metadata": {
        "id": "_vKrI37kHCH_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bT1cXEnqG_Ok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}